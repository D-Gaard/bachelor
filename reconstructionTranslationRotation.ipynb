{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lineRenderWorldSetup as LR\n",
    "import cv2\n",
    "import numpy as np\n",
    "from mayavi import mlab\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from natsort import natsorted\n",
    "import os\n",
    "import _3dTo2dSetup as D3\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix\n",
    "from scipy.ndimage import zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['model_uncertainty\\\\rotated\\\\offset_5\\\\R_-00_-00_5_0-5.npy', 'model_uncertainty\\\\rotated\\\\offset_5\\\\R_-00_-00_5_00.npy', 'model_uncertainty\\\\rotated\\\\offset_5\\\\R_-00_-00_5_5-5.npy', 'model_uncertainty\\\\rotated\\\\offset_5\\\\R_-00_-00_5_05.npy', 'model_uncertainty\\\\rotated\\\\offset_5\\\\R_-00_-00_5_50.npy', 'model_uncertainty\\\\rotated\\\\offset_5\\\\R_-00_-00_5_55.npy', 'model_uncertainty\\\\rotated\\\\offset_5\\\\R_-00_-00_5_-5-5.npy', 'model_uncertainty\\\\rotated\\\\offset_5\\\\R_-00_-00_5_-50.npy', 'model_uncertainty\\\\rotated\\\\offset_5\\\\R_-00_-00_5_-55.npy']\n"
     ]
    }
   ],
   "source": [
    "# Load projections\n",
    "path = r\"model_uncertainty\\rotated\\offset_5\" #CHANGE NAME BASED ON OFFSET!\n",
    "proj_path = natsorted(glob(os.path.join(path, \"*.npy\")))\n",
    "box_dim = LR.BOX_DIM\n",
    "real_box_dim = 301\n",
    "\n",
    "#load 3D model\n",
    "path_real = r\"solid_400001-segmentation-solid_400001-label.nrrd\"\n",
    "real_box = D3.get3dFigure(real_box_dim, path_real)\n",
    "real_box = np.where(zoom(np.copy(real_box),1.4) >= 1, 1, 0)\n",
    "\n",
    "# order projection based on custom selection (see report)\n",
    "print(proj_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['model_uncertainty\\\\rotated\\\\offset_5\\\\R_-00_-00_5_00.npy', 'model_uncertainty\\\\rotated\\\\offset_5\\\\R_-00_-00_5_0-5.npy', 'model_uncertainty\\\\rotated\\\\offset_5\\\\R_-00_-00_5_5-5.npy', 'model_uncertainty\\\\rotated\\\\offset_5\\\\R_-00_-00_5_05.npy', 'model_uncertainty\\\\rotated\\\\offset_5\\\\R_-00_-00_5_50.npy', 'model_uncertainty\\\\rotated\\\\offset_5\\\\R_-00_-00_5_55.npy', 'model_uncertainty\\\\rotated\\\\offset_5\\\\R_-00_-00_5_-5-5.npy', 'model_uncertainty\\\\rotated\\\\offset_5\\\\R_-00_-00_5_-50.npy', 'model_uncertainty\\\\rotated\\\\offset_5\\\\R_-00_-00_5_-55.npy']\n"
     ]
    }
   ],
   "source": [
    "#place 0 rotation box as first elm in list (for rotation only)\n",
    "temp = [proj_path[1]]\n",
    "for i in range(len(proj_path)):\n",
    "  if i != 1:\n",
    "    temp.append(proj_path[i])\n",
    "proj_path = temp\n",
    "\n",
    "print(proj_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_score(true, pred):\n",
    "  true_bool = np.asarray(true).astype(np.bool)\n",
    "  pred_bool = np.asarray(pred).astype(np.bool)\n",
    "  inter = np.logical_and(true_bool,pred_bool)\n",
    "\n",
    "  return (2* inter.sum()) / (true_bool.sum()\n",
    "    + pred_bool.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "#add padding for reconstruction comparison\n",
    "padding = int((box_dim - real_box.shape[0])/2)\n",
    "print(padding)\n",
    "real_box = np.pad(real_box, [(padding, padding), (padding, padding),(padding, padding)], mode='constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics using  2nd  projection: [tn, fp, fn, tp, dice, precision, recall] [0.9499  0.03249 0.00044 0.01716 0.51029 0.3456  0.97483]\n",
      "Metrics using  3nd  projection: [tn, fp, fn, tp, dice, precision, recall] [0.94934 0.03306 0.00067 0.01693 0.50096 0.33869 0.9617 ]\n",
      "Metrics using  4nd  projection: [tn, fp, fn, tp, dice, precision, recall] [0.94831 0.03409 0.00037 0.01723 0.50003 0.33577 0.97894]\n",
      "Metrics using  5nd  projection: [tn, fp, fn, tp, dice, precision, recall] [0.94891 0.03348 0.00052 0.01708 0.50111 0.33779 0.97021]\n",
      "Metrics using  6nd  projection: [tn, fp, fn, tp, dice, precision, recall] [0.9486  0.0338  0.00063 0.01697 0.49646 0.3343  0.96413]\n",
      "Metrics using  7nd  projection: [tn, fp, fn, tp, dice, precision, recall] [0.95036 0.03203 0.00057 0.01704 0.51105 0.34719 0.96778]\n",
      "Metrics using  8nd  projection: [tn, fp, fn, tp, dice, precision, recall] [0.94914 0.03326 0.00049 0.01712 0.50363 0.33981 0.97243]\n",
      "Metrics using  9nd  projection: [tn, fp, fn, tp, dice, precision, recall] [0.94832 0.03408 0.00046 0.01714 0.49817 0.33469 0.97386]\n"
     ]
    }
   ],
   "source": [
    "#Calculate metrics for intersection of projections\n",
    "np.set_printoptions(precision=5, suppress = True)\n",
    "metrics= []\n",
    "base_proj = np.load(r\"model_uncertainty\\normal\\1_N-87_+27.npy\")\n",
    "\n",
    "for i in range(1,len(proj_path)): #skip first as this contains 0 offset\n",
    "  #calculate box intersection\n",
    "  base_box = np.copy(base_proj)\n",
    "  current_box = np.load(proj_path[i])\n",
    "  box_total = base_box + current_box\n",
    "  box_total = np.where(box_total == 2, 1, 0)\n",
    "\n",
    "  #calculate metrics for each reconstruction\n",
    "  TN, FP, FN, TP = confusion_matrix(real_box.flatten(), box_total.flatten()).ravel()\n",
    "  total = TN + FP + FN + TP\n",
    "  accuracy = (TP + TN)/(FP+FN+TP+TN)\n",
    "  precision = TP/(TP+FP)\n",
    "  recall = TP/(TP+FN)\n",
    "  dice = dice_score(real_box.flatten(), box_total.flatten())\n",
    "  #f1 = 2*(precision*recall)/(precision+recall)\n",
    "  scores = np.array([TN/total, FP/total, FN/total, TP/total, dice, precision, recall])\n",
    "  metrics.append(scores)\n",
    "  print(\"Metrics using \", str(i+1) + \"nd\" , \" projection: [tn, fp, fn, tp, dice, precision, recall]\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average metrics for given offset: [tn, fp, fn, tp, dice, precision, recall] [0.94832 0.03408 0.00046 0.01714 0.49817 0.33469 0.97386]\n"
     ]
    }
   ],
   "source": [
    "# average metric accross the different projections\n",
    "metrics = np.array(metrics)\n",
    "avg_metric = np.zeros(len(metrics[0]))\n",
    "for metric in metrics:\n",
    "    avg_metric += metric\n",
    "\n",
    "avg_metric = avg_metric/len(metrics)\n",
    "\n",
    "print(\"Average metrics for given offset: [tn, fp, fn, tp, dice, precision, recall]\", scores)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f8665132f1068c6d656335a3a93d4e1e9cc43466a542cc440a9c028e42f97746"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
